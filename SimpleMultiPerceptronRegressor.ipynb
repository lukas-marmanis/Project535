{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Author:Anthony Zalev\n",
    "Goal: Illistrate catestrophic forgetting using the covid dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import sqlite3 as sq\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set Seed and Set device functions obtained from: https://deeplearning.neuromatch.io/tutorials/W3D4_ContinualLearning/student/W3D4_Tutorial1.html#section-1-1-a-brief-example-of-catastrophic-forgetting\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_seed(seed=None, seed_torch=True):\n",
    "    \"\"\"\n",
    "    Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "    Args:\n",
    "      seed : Integer\n",
    "        A non-negative integer that defines the random state. Default is `None`.\n",
    "      seed_torch : Boolean\n",
    "        If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "        must be imported. Default is `True`.\n",
    "\n",
    "    Returns:\n",
    "      Nothing.\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"\n",
    "    DataLoader will reseed workers following randomness in\n",
    "    multi-process data loading algorithm.\n",
    "\n",
    "    Args:\n",
    "      worker_id: integer\n",
    "        ID of subprocess to seed. 0 means that\n",
    "        the data will be loaded in the main process\n",
    "        Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    \"\"\"\n",
    "    Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "    Args:\n",
    "      None\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"GPU is not enabled in this notebook. \\n\"\n",
    "              \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook. \\n\"\n",
    "              \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n",
    "              \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n",
    "\n",
    "    return device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Domain incremental learning:\n",
    "\n",
    "This nueral net will have to learn to identify the cases/death ratio over time first before vaccines and then after they come out."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conn = sq.connect('datasets/{}.sqlite'.format(\"master\")) #create file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following model based on\n",
    "\n",
    "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-create-a-neural-network-for-regression-with-pytorch.md"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#instatiate neural net.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(59, 512), #input layer\n",
    "        nn.ReLU(), #hidden 1\n",
    "        nn.ReLU(),\n",
    "        nn.ReLU(),\n",
    "        nn.ReLU(),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 128), #hidden 2\n",
    "        nn.ReLU(), # hidden 3\n",
    "        nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "          Forward pass\n",
    "        '''\n",
    "        return self.layers(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set random seed and load initial data from 2020\n",
    "#torch.manual_seed(42) # group 42 for the win.\n",
    "dataset_df = pd.read_sql_query(\"SELECT * FROM combined_weekly_encoded_scaled\", conn)\n",
    "year_week = pd.read_sql_query(\"SELECT year_week FROM combined_weekly_encoded_scaled\", conn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#test\n",
    "year_week[\"year_week\"][0][0:4] + year_week[\"year_week\"][0][5:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tranform date to int for range selection\n",
    "dataset_df[\"year_week\"] = dataset_df[\"year_week\"].transform(lambda x: x[0:4] + x[5:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT * FROM dataset_df\n",
    "        WHERE year_week < 202056\n",
    "\"\"\"\n",
    "dataset_2020_df = ps.sqldf(query, locals())\n",
    "dataset_2020_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT * FROM dataset_df\n",
    "        WHERE year_week > 202100\n",
    "\"\"\"\n",
    "dataset_rest_df = ps.sqldf(query, locals())\n",
    "dataset_rest_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset_2020_df.drop(['year_week', 'fips', 'avg_deaths'], axis = 1).to_numpy()\n",
    "Y = dataset_2020_df[['avg_deaths']].to_numpy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size = 0.33 , random_state = 15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_2 = dataset_rest_df.drop(['year_week', 'fips', 'avg_deaths'], axis = 1).to_numpy()\n",
    "Y_2 = dataset_rest_df[['avg_deaths']].to_numpy()\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(X_2,Y_2,test_size = 0.33 , random_state = 15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_function = nn.L1Loss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, x_train, t_train, optimizer, epoch, device):\n",
    "    loss_list = []\n",
    "    \"\"\"\n",
    "    Train function\n",
    "\n",
    "    Args:\n",
    "      model: Net() type\n",
    "        Instance of the multilayer CNN\n",
    "      x_train: np.ndarray\n",
    "        Training data\n",
    "      t_train: np.ndarray\n",
    "        Labels corresponding to the training data\n",
    "      optimizer: torch.optim type\n",
    "        Implements Adam algorithm.\n",
    "      epoch: int\n",
    "        Number of epochs\n",
    "      device: string\n",
    "        CUDA/GPU if available, CPU otherwise\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    for start in range(0, len(t_train)-1, 256):\n",
    "        end = start + 256\n",
    "        x = torch.from_numpy(x_train[start:end])\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "        else:\n",
    "            x = x.type(torch.FloatTensor)\n",
    "        y = torch.from_numpy(t_train[start:end]).long()\n",
    "        y = y.type(torch.FloatTensor)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "        loss = loss_function(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, x_test, t_test,device):\n",
    "    \"\"\"\n",
    "    Test function.\n",
    "\n",
    "    Args:\n",
    "      model: Net() type\n",
    "        Instance of the multilayer CNN\n",
    "      x_test: np.ndarray\n",
    "        Test data\n",
    "      t_test: np.ndarray\n",
    "        Labels corresponding to the test data\n",
    "      device: string\n",
    "        CUDA/GPU if available, CPU otherwise\n",
    "\n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct, test_loss = 0, 0\n",
    "    target_mean = torch.mean(torch.from_numpy(t_test))\n",
    "    y = torch.from_numpy(t_test)\n",
    "    y = y.to(device)\n",
    "    x = torch.from_numpy(x_test)\n",
    "    x = x.type(torch.cuda.FloatTensor)\n",
    "    x = x.to(device)\n",
    "    output = model(x)\n",
    "    #print(target_mean)\n",
    "    #print(output)\n",
    "\n",
    "    ss_tot = torch.sum((output - target_mean) ** 2)\n",
    "    ss_res =  torch.sum((y - output) ** 2)\n",
    "    for start in range(0, len(t_test)-1, 256):\n",
    "        end = start + 256\n",
    "        with torch.no_grad():\n",
    "            x = torch.from_numpy(x_test[start:end])\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.type(torch.cuda.FloatTensor)\n",
    "            else:\n",
    "                x = x.type(torch.FloatTensor)\n",
    "            y = torch.from_numpy(t_test[start:end]).long()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            test_loss += loss_function(output, y).item()  # Sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # Get the index of the max logit\n",
    "\n",
    "\n",
    "\n",
    "    test_loss /= len(t_test)\n",
    "    r2 = 1 - ss_res/ss_tot\n",
    "    print('Test set: Average loss: {:.4f}, R^2: {:.4f}\\n'.format(test_loss, r2))\n",
    "    return r2, test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "  # Initialize the MLP\n",
    "mlp = MLP().to(DEVICE)\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=.01)\n",
    "nEpochs = 50\n",
    "loss_origial = []\n",
    "loss_permutated = []\n",
    "finalr2 = 0\n",
    "permutatedr2 = 0\n",
    "for epoch in range(1, nEpochs+1):\n",
    "    train(mlp, x_train, y_train, optimizer, epoch, device=DEVICE)\n",
    "    finalr2, loss_1 = test(mlp, x_test, y_test, device=DEVICE)\n",
    "    permutated_r2 , loss_2 = test(mlp, x_test_2, y_test_2, device = DEVICE)\n",
    "    loss_origial.append([loss_1, epoch, 'original'])\n",
    "    loss_permutated.append([loss_2, epoch, 'next_series'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(finalr2.item(), permutated_r2.item())\n",
    "#df = {'testYears' : ['2020', '2021-2022'], 'adjustedr2' : [finalr2.item(), permutated_r2.item()]}\n",
    "#sns.barplot(x = \"testYears\", y = \"adjustedr2\" , data = df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_origial.extend(loss_permutated)\n",
    "loss_origial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lineplot_df = pd.DataFrame(loss_origial, columns = ['loss', 'epoch', 'timeseries'])\n",
    "lineplot_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "plot = sns.lineplot( x= 'epoch', y = 'loss', hue = 'timeseries', data = lineplot_df)\n",
    "plot.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "plot.set(title = \"Loss Convergence For Test Sets From During and Subsequent Time Series\")\n",
    "plt.savefig('MLP_test_set_convergence.png',\n",
    "            dpi=300,transparent=True,\n",
    "            bbox_inches = 'tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp2 = MLP().to(DEVICE)\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp2.parameters(), lr=.001)\n",
    "nEpochs = 50\n",
    "\n",
    "finalr2_train2 = 0\n",
    "permutated_r2_train2 = 0\n",
    "for epoch in range(1, nEpochs+1):\n",
    "    train(mlp2, x_train_2, y_train_2, optimizer, epoch, device=DEVICE)\n",
    "    finalr2_train2 = test(mlp2, x_test_2, y_test_2, device=DEVICE)\n",
    "    permutated_r2_train2  = test(mlp2, x_test, y_test, device = DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(finalr2_train2, permutated_r2_train2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'testYears' : ['2020', '2021-2022'], 'adjustedr2' : [permutated_r2_train2.item(), finalr2_train2.item()],  \"trainingData\" :  ['2021-2022', '2021-2022']})\n",
    "#sns.barplot(x = \"testYears\", y = \"adjustedr2\" , data = df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame({'testYears' : ['2020', '2021-2022'], 'adjustedr2' : [finalr2.item(), permutated_r2.item()], \"trainingData\" :  ['2020', '2020']})\n",
    "sns.barplot(x = \"testYears\", y = \"adjustedr2\" , data = df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3 = pd.concat([df, df_2])\n",
    "df_3.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ordering= pd.DataFrame({'testYears' : ['2020', '2021-2022']})\n",
    "\n",
    "plt.figure(figsize = (16,9))\n",
    "plot = sns.barplot(x = \"trainingData\", y = \"adjustedr2\" , hue = 'testYears' , data = df_3, order = ordering['testYears'])\n",
    "plot.set_xlabel(\"Time Range of Training Data\", fontsize = 15, )\n",
    "plot.set_ylabel(\"R^2\", fontsize = 15)\n",
    "plot.legend(title = \"Test Periods\", bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "plot.set(title = \"R^2 for Test Data trained on Different Time Periods\")\n",
    "plt.savefig('catestrophic_forgetting.png',\n",
    "            dpi = 300,\n",
    "             transparent = True,\n",
    "            bbox_inches = 'tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EWC MODEL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}